# ToxBlocker
Technica 2021 Hackathon project

Social media can be a breeding ground for nefarious actors promoting hate and toxicity at the expense of other users, who are sadly subjected to this content. For users who want to avoid toxic content online,  we need a mechanism for identifying such content and alerting users to its presence. That's where ToxBlocker comes in.

## Usage
- Download the dataset used to train the LSTM model here: [https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview]
- Run the notebook ToxBlocker.ipynb to pull in the data, perform Natural Language Processing, and train save the model
- Run the app.py file using Flask
- Open the HTML file in a browser (only tested with Google Chrome) to launch the Web App and interact with it
